Shirts2017
    Reading this to better understand reproducibility study
    Comparing results across engines. 
    How the charges calculated (whole molecule or fragment) affects the result and this is often not reported.
    Compare potential energy, density, enthalpy
    started with one file and converted into another and then another
    They also used hard cutoff
    They found errors due to differences in Colomb's constant!
Rizzi2020
    binding energies of ligand/protein. comparing engines. results suggest the forcefield + partial charges are not enough to ensure reproducibility. Berendsen barostat introduces artifacts.
    Binding matters for small molecule drug discovery.
    Enhanced sampling helps with proteins becausethere are areas in their configurational space that are difficult to probe with short simulations.
    Not all of the engines had the same parameters
    Differences between methods impact force field development
    - ffs can only be expected to be accurate with the same parameters
    Replicates are important to understand the uncertainty in the measurement
    Larger and more varied test set gives more information about the method

TODO read
Zasada2020



https://doi.org/10.1016/j.jtbi.2010.12.024
    (TODO read) how to make protein study reproducibile
John D. Blischak, Emily R. Davenport, and Greg Wilson: "A Quick Introduction to Version Control with Git and GitHub" PLoS Computational Biology, 2016.
    details how and why to use version control software as a scientist

https://semver.org/spec/v2.0.0.html
    semantic versioning guide -- how to decide on the version number for a codebase

Matthew Gentzkow and Jesse Shapiro: "Code and Data for the Social Sciences: A Practitioner's Guide.", 2014.
    gives accounts of what is wrong with coding in the sciences and gives guidelines aimed at fixing these issues. Specifically, version control, abstraction, using tools like github issues/project boards to manage collaboration and development, documentation, etc.

Damien Irving: "A minimum standard for publishing computational results in the weather and climate sciences", 2015.
    many good references (TODO) discusses reproducibility crisis and how published work using software can be more reproducible

William Stafford Noble: "A Quick Guide to Organizing Computational Biology Projects." PLoS Computational Biology, 2009.
    could use this as an example of how managing a dataspace is tricky and why we use signac

Yasset Perez-Riverol, Laurent Gatto, Rui Wang, Timo Sachsenberg, Julian Uszkoreit, Felipe da Veiga Leprevost, Christian Fufezan, Tobias Ternent, Stephen J. Eglen, Daniel S. Katz, Tom J. Pollard, Alexander Konovalov, Robert M. Flight, Kai Blin and Juan Antonio Vizcaíno: "Ten Simple Rules for Taking Advantage of Git and GitHub" PLoS Comput Biol 12(7): e1004947, 2016.
    straightforward guide of how to use github features to streamline code development

Greg Wilson, D. A. Aruliah, C. Titus Brown, Neil P. Chue Hong, Matt Davis, Richard T. Guy, Steven H. D. Haddock, Kathryn D. Huff, Ian M. Mitchell, Mark D. Plumbley, Ben Waugh, Ethan P. White, and Paul Wilson: "Best Practices for Scientific Computing" PLoS Biology, 2014.
    Many great references (TODO) good overview of best practices in developing software

Cito J., Ferme V., Gall H.C. (2016) Using Docker Containers to Improve Reproducibility in Software and Web Engineering Research. In: Bozzon A., Cudre-Maroux P., Pautasso C. (eds) Web Engineering. ICWE 2016. Lecture Notes in Computer Science, vol 9671. Springer, Cham. https://doi.org/10.1007/978-3-319-38791-8_58
    Docker containers can help solve reproducibility issues

Björn Grüning, John Chilton, Johannes Köster, Ryan Dale, Nicola Soranzo, Marius van den Beek, Jeremy Goecks, Rolf Backofen, Anton Nekrutenko, James Taylor, Practical Computational Reproducibility in the Life Sciences, Cell Systems, Volume 6, Issue 6, 2018, Pages 631-635, ISSN 2405-4712, https://doi.org/10.1016/j.cels.2018.03.014.
    Details how containers (and even VMs) can be used to aid reproducibility of computational works

Towards Molecular Simulations that are Transparent, Reproducible, Usable By Others, and Extensible (TRUE) Matthew W. Thompson, Justin B. Gilmer, Ray A. Matsumoto, Co D. Quach, Parashara Shamaprasad, Alexander H. Yang, Christopher R. Iacovella, Clare McCabe, Peter T. Cummings. https://arxiv.org/abs/2003.02031
    many good refs (TODO) outlines mosdef, reproducibility crisis and TRUE

Eric Jankowski, Neale Ellyson, Jenny W. Fothergill, Michael M. Henry, Mitchell H. Leibowitz, Evan D. Miller, Mone’t Alberts, Samantha Chesser, Jaime D. Guevara, Chris D. Jones, Mia Klopfenstein, Kendra K. Noneman, Rachel Singleton, Ramon A. Uriarte-Mendoza, Stephen Thomas, Carla E. Estridge, Matthew L. Jones, Perspective on coarse-graining, cognitive load, and materials simulation, Computational Materials Science, Volume 171, 2020, 109129, ISSN 0927-0256, https://doi.org/10.1016/j.commatsci.2019.109129.
    our perspective paper. many good refs, overview of onboarding and best practices particularly good


# thinking about reproducibility today
https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006649#sec004
Ten simple rules on how to create open access and reproducible molecular simulations of biological system
    super short straightforward rules for reproducibility

https://doi.org/10.1016/j.bbagen.2014.09.007
    Shows that DNA conformation can be obtained using different simulation engines with the same forcefield.
    describes how they did it.
    some hilarity ensues when they mention hand-editing text files.
    they use the same engines but on different architectures


Statistically optimal analysis of samples from multiple equilibrium states
J. Chem. Phys. 129, 124105 (2008); https://doi.org/10.1063/1.2978177 
    mbar 
